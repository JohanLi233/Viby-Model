import os
import sys
import time
import torch
import torch.nn.functional as F
import numpy as np

# è®¾ç½®ç¯å¢ƒå˜é‡å’Œè·¯å¾„
os.environ["CAUSAL_CONV1D_METAL_PATH"] = os.path.join(
    os.path.dirname(os.path.abspath(__file__)), "causal_conv1d.metal"
)
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def bench_robust(fn, warmup=10, iters=50, runs=5):
    """æ›´ç¨³å®šçš„æ€§èƒ½æµ‹è¯•å‡½æ•°"""
    results = []

    for run in range(runs):
        # æ¯æ¬¡è¿è¡Œå‰éƒ½é¢„çƒ­
        for _ in range(warmup):
            fn()
        torch.mps.synchronize()

        # æµ‹é‡å¤šæ¬¡è¿­ä»£
        times = []
        for _ in range(iters):
            t0 = time.time()
            fn()
            torch.mps.synchronize()
            t1 = time.time()
            times.append(t1 - t0)

        # å»æ‰æœ€é«˜å’Œæœ€ä½å€¼ï¼Œè®¡ç®—å¹³å‡å€¼
        times = sorted(times)[2:-2]  # å»æ‰å‰åå„2ä¸ªæå€¼
        avg_time = sum(times) / len(times)
        results.append(avg_time)

    # å»æ‰æœ€é«˜å’Œæœ€ä½çš„è¿è¡Œï¼Œè¿”å›ä¸­ä½æ•°
    results = sorted(results)[1:-1]
    return sum(results) / len(results)


def bench_robust_stable(fn, warmup=25, iters=100, runs=5, desc=""):
    """
    ä¸€ä¸ªæ›´ç¨³å®šã€æ›´å¥å£®çš„æ€§èƒ½æµ‹è¯•å‡½æ•°ã€‚

    ä¸»è¦æ”¹è¿›:
    1. åœ¨æ‰€æœ‰è¿è¡Œ(runs)å¼€å§‹å‰è¿›è¡Œä¸€æ¬¡å……åˆ†çš„é¢„çƒ­ã€‚
    2. æ¯æ¬¡æµ‹é‡éƒ½ä¸¥æ ¼ä½¿ç”¨ torch.mps.synchronize() åŒ…è£¹ã€‚
    3. è¿”å›å¤šæ¬¡è¿è¡Œ(runs)çš„ã€ä¸­ä½æ•°ã€‘æ—¶é—´ï¼Œå®ƒå¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿã€‚
    4. åŒæ—¶è¿”å›æ ‡å‡†å·®ï¼Œç”¨äºè¯„ä¼°ç»“æœçš„ç¨³å®šæ€§ã€‚
    """
    # é›†ä¸­é¢„çƒ­ï¼šåœ¨æ‰€æœ‰è®¡æ—¶å¼€å§‹å‰ï¼Œè®©GPUè¾¾åˆ°ç¨³å®šå·¥ä½œçŠ¶æ€
    if desc:
        print(f"{desc:<20} {'é¢„çƒ­ä¸­...':<10}", end="\r")
    for _ in range(warmup):
        fn()
    torch.mps.synchronize()

    run_times = []
    for _ in range(runs):
        # æ¯æ¬¡è¿è¡Œéƒ½ç‹¬ç«‹è®¡æ—¶ï¼Œæ›´èƒ½æŠµæŠ—ç³»ç»Ÿå¹²æ‰°
        torch.mps.synchronize()
        t0 = time.time()
        for _ in range(iters):
            fn()
        torch.mps.synchronize()
        t1 = time.time()

        # è®¡ç®—å•æ¬¡è¿­ä»£çš„å¹³å‡æ—¶é—´
        avg_iter_time = (t1 - t0) / iters
        run_times.append(avg_iter_time)

    # ç»Ÿè®¡åˆ†æï¼šè®¡ç®—ä¸­ä½æ•°å’Œæ ‡å‡†å·®
    median_time = np.median(run_times)
    std_dev = np.std(run_times)

    return median_time, std_dev


def causal_conv1d_reference(x, weight, bias=None, silu_activation=False):
    """PyTorch å‚è€ƒå®ç°"""
    batch, dim, seqlen = x.shape
    width = weight.shape[1]

    # ä½¿ç”¨ F.conv1d å®ç°å› æœå·ç§¯
    x_padded = F.pad(x, (width - 1, 0))  # å·¦ä¾§å¡«å……
    out = F.conv1d(x_padded, weight.unsqueeze(1), bias=bias, groups=dim, padding=0)
    out = out[:, :, :seqlen]  # æˆªå–åˆ°åŸå§‹é•¿åº¦

    if silu_activation:
        out = F.silu(out)

    return out


def canon_forward_reference(x_btd, weight_dw, bias_d=None, activation: bool = True):
    """
    å‚è€ƒç‰ˆ Canon å‰å‘ï¼šè¾“å…¥ [B, T, D]ï¼Œä¸ lingua çš„ Canon ä¸€è‡´ã€‚
    - depthwise ç»„å·ç§¯ (groups=D)ï¼Œkernel æƒé‡å½¢çŠ¶ä¸º [D, W]
    - å› æœå¡«å…… padd_left=W-1
    - å¯é€‰ SiLU æ¿€æ´»
    è¿”å›åŒå½¢çŠ¶ [B, T, D]
    """
    b, t, d = x_btd.shape
    w = weight_dw.shape[1]
    x_bdt = x_btd.movedim(-1, -2)  # [B, D, T]
    x_pad = F.pad(x_bdt, (w - 1, 0))
    y = F.conv1d(x_pad, weight_dw.unsqueeze(1), bias=bias_d, groups=d)
    y = y[..., :t]
    if activation:
        y = F.silu(y)
    return y.movedim(-2, -1)


def main():
    print("ğŸš€ Causal Conv1D MPS æ€§èƒ½æµ‹è¯•")

    assert torch.backends.mps.is_available(), "MPS not available"

    try:
        import my_mps_extension._C as mps_ext

        print("âœ… æˆåŠŸåŠ è½½ MPS æ‰©å±•")
    except ImportError as e:
        print(f"âŒ æ— æ³•åŠ è½½æ‰©å±•: {e}")
        return

    device = torch.device("mps")

    # æµ‹è¯•é…ç½®ï¼š(batch, dim, seqlen, width)
    test_configs = [
        (1, 64, 128, 4),  # å°è§„æ¨¡
        (2, 128, 256, 4),  # ä¸­ç­‰è§„æ¨¡
        (4, 256, 512, 4),  # å¤§è§„æ¨¡
        (1, 512, 1024, 4),  # è¶…å¤§è§„æ¨¡
        (8, 64, 128, 4),  # å¤§æ‰¹é‡
    ]

    print(
        f"{'Config':<20} {'MPS(ms)':<10} {'PyTorch(ms)':<12} {'Speedup':<10} {'MPS_StdDev(%)':<15} {'Correct':<8}"
    )
    print("-" * 80)

    for batch, dim, seqlen, width in test_configs:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        x = torch.randn(batch, dim, seqlen, device=device, dtype=torch.float32)
        weight = torch.randn(dim, width, device=device, dtype=torch.float32)
        bias = torch.randn(dim, device=device, dtype=torch.float32)

        config_str = f"{batch}Ã—{dim}Ã—{seqlen}Ã—{width}"

        try:
            # MPS å®ç°
            def run_mps():
                return mps_ext.causal_conv1d_fwd(
                    x.contiguous(), weight.contiguous(), bias.contiguous(), False
                )

            # PyTorch å‚è€ƒå®ç°
            def run_torch():
                return causal_conv1d_reference(x, weight, bias, False)

            # æ€§èƒ½æµ‹è¯•ï¼ˆä½¿ç”¨æ›´ç¨³å®šçš„æ–¹æ³•ï¼‰
            t_mps, std_mps = bench_robust_stable(
                run_mps, warmup=1000, iters=500, runs=21, desc=config_str
            )
            t_torch, _ = bench_robust_stable(
                run_torch, warmup=1000, iters=500, runs=21, desc=config_str
            )

            # æ­£ç¡®æ€§éªŒè¯
            result_mps = run_mps()
            result_torch = run_torch()
            max_diff = torch.max(torch.abs(result_mps - result_torch)).item()
            is_correct = max_diff < 1e-4

            speedup = t_torch / t_mps
            std_percent_mps = (std_mps / t_mps) * 100 if t_mps > 0 else 0
            print(
                f"{config_str:<20} {t_mps * 1000:<10.2f} {t_torch * 1000:<12.2f} {speedup:<10.2f} {std_percent_mps:<15.2f} {'âœ…' if is_correct else 'âŒ':<8}"
            )

            if not is_correct:
                print(f"  âš ï¸  æœ€å¤§å·®å¼‚: {max_diff:.6f}")

            # åœ¨ä¸åŒé…ç½®ä¹‹é—´ç¨å¾®ä¼‘æ¯ï¼Œç¼“è§£æ¸©åº¦å½±å“
            time.sleep(1)

        except Exception as e:
            print(
                f"{config_str:<20} {'ERROR':<10} {'ERROR':<12} {'ERROR':<10} {'ERROR':<15} {'âŒ':<8}"
            )
            print(f"  é”™è¯¯: {e}")

    # SiLU æ¿€æ´»å‡½æ•°æ€§èƒ½æµ‹è¯•
    print("\nğŸ”¥ SiLU æ¿€æ´»å‡½æ•°æ€§èƒ½æµ‹è¯•")
    print(
        f"{'Config':<20} {'MPS+SiLU(ms)':<14} {'PyTorch+SiLU(ms)':<17} {'Speedup':<10} {'MPS_StdDev(%)':<15}"
    )
    print("-" * 90)

    # é€‰æ‹©ä¸­ç­‰è§„æ¨¡æµ‹è¯•æ¿€æ´»å‡½æ•°
    batch, dim, seqlen, width = 2, 128, 256, 4
    config_str = f"{batch}Ã—{dim}Ã—{seqlen}Ã—{width}"

    torch.manual_seed(42)
    x = torch.randn(batch, dim, seqlen, device=device, dtype=torch.float32)
    weight = torch.randn(dim, width, device=device, dtype=torch.float32)
    bias = torch.randn(dim, device=device, dtype=torch.float32)

    try:

        def run_mps_silu():
            return mps_ext.causal_conv1d_fwd(
                x.contiguous(), weight.contiguous(), bias.contiguous(), True
            )

        def run_torch_silu():
            return causal_conv1d_reference(x, weight, bias, True)

        t_mps_silu, std_mps_silu = bench_robust_stable(
            run_mps_silu, warmup=1000, iters=400, runs=21, desc=config_str
        )
        t_torch_silu, _ = bench_robust_stable(
            run_torch_silu, warmup=1000, iters=400, runs=21, desc=config_str
        )
        speedup_silu = t_torch_silu / t_mps_silu
        std_percent_mps_silu = (
            (std_mps_silu / t_mps_silu) * 100 if t_mps_silu > 0 else 0
        )

        print(
            f"{config_str:<20} {t_mps_silu * 1000:<14.2f} {t_torch_silu * 1000:<17.2f} {speedup_silu:<10.2f} {std_percent_mps_silu:<15.2f}"
        )

    except Exception as e:
        print(f"{config_str:<20} {'ERROR':<12} {'ERROR':<15} {'ERROR':<10}")
        print(f"  é”™è¯¯: {e}")

    print("\nğŸ“Š æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
    print(
        "ğŸ’¡ æç¤º: Speedup > 1.0 è¡¨ç¤º MPS å®ç°æ›´å¿«ã€‚StdDev(%) è¶Šå°ï¼Œè¡¨ç¤ºæµ‹è¯•ç»“æœè¶Šç¨³å®šã€‚"
    )

    # =====================
    # Canon åœºæ™¯ï¼ˆB, T, Dï¼‰åŸºå‡†
    # =====================
    print("\nğŸ§ª Canon ä½¿ç”¨åœºæ™¯åŸºå‡† (B,T,D æ¥å£)")
    print(
        f"{'Config':<24} {'MPS(ms)':<10} {'PyTorch(ms)':<12} {'Speedup':<10} {'MPS_StdDev(%)':<15} {'Correct':<8}"
    )
    print("-" * 96)

    device = torch.device("mps")
    torch.manual_seed(123)
    canon_configs = [
        # (B, T, D, W)
        (1, 128, 512, 4),
        (2, 256, 768, 4),
        (4, 512, 1024, 4),
    ]

    try:
        import my_mps_extension._C as mps_ext
    except Exception as e:
        print(f"æ— æ³•åŠ è½½æ‰©å±•ï¼Œè·³è¿‡ Canon åœºæ™¯æµ‹è¯•: {e}")
        return

    for bsz, seqlen, dim, width in canon_configs:
        x_btd = torch.randn(bsz, seqlen, dim, device=device)
        weight_dw = torch.randn(dim, width, device=device)
        bias_d = torch.randn(dim, device=device)

        cfg = f"B{bsz} T{seqlen} D{dim} W{width}"

        def run_mps_canon():
            # è½¬ä¸º [B, D, T] è·¯å¾„ä»¥å¤ç”¨æ ¸
            x_bdt = x_btd.movedim(-1, -2).contiguous()
            y_bdt = mps_ext.causal_conv1d_fwd(
                x_bdt, weight_dw.contiguous(), bias_d.contiguous(), True
            )
            return y_bdt.movedim(-2, -1)

        def run_ref_canon():
            return canon_forward_reference(x_btd, weight_dw, bias_d, activation=True)

        t_ref, _ = bench_robust_stable(
            run_ref_canon, warmup=1000, iters=500, runs=21, desc=cfg
        )

        t_mps, std_mps = bench_robust_stable(
            run_mps_canon, warmup=1000, iters=500, runs=21, desc=cfg
        )
        y_mps = run_mps_canon()
        y_ref = run_ref_canon()
        max_diff = torch.max(torch.abs(y_mps - y_ref)).item()
        is_ok = max_diff < 1e-4

        sp = t_ref / t_mps
        std_pct = (std_mps / t_mps) * 100 if t_mps > 0 else 0
        print(
            f"{cfg:<24} {t_mps*1000:<10.2f} {t_ref*1000:<12.2f} {sp:<10.2f} {std_pct:<15.2f} {'âœ…' if is_ok else 'âŒ':<8}"
        )

        if not is_ok:
            print(f"  âš ï¸ æœ€å¤§å·®å¼‚: {max_diff:.6f}")


if __name__ == "__main__":
    main()
